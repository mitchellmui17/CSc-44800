{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a href=\"https://colab.research.google.com/github/mitchellmui17/CSc-44800/blob/main/Assignment04/Assignment04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "S8PKiVJaL_AW",
    "outputId": "23c2a4cd-0c53-4a1c-c454-7ed87e392a8c"
   },
   "outputs": [],
   "source": [
    "# Imports and pip installations (if needed)\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A05Q5B0_NUX9"
   },
   "source": [
    "# Part 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "YZ4MUsbXNZ0P",
    "outputId": "77e7a628-792f-4d28-b7b1-e06f4db3efd3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                 5.1               3.5                1.4               0.2\n",
       "1                 4.9               3.0                1.4               0.2\n",
       "2                 4.7               3.2                1.3               0.2\n",
       "3                 4.6               3.1                1.5               0.2\n",
       "4                 5.0               3.6                1.4               0.2\n",
       "5                 5.4               3.9                1.7               0.4\n",
       "6                 4.6               3.4                1.4               0.3\n",
       "7                 5.0               3.4                1.5               0.2\n",
       "8                 4.4               2.9                1.4               0.2\n",
       "9                 4.9               3.1                1.5               0.1\n",
       "10                5.4               3.7                1.5               0.2\n",
       "11                4.8               3.4                1.6               0.2\n",
       "12                4.8               3.0                1.4               0.1\n",
       "13                4.3               3.0                1.1               0.1\n",
       "14                5.8               4.0                1.2               0.2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "iris = load_iris()\n",
    "\n",
    "# Output the first 15 rows of the data\n",
    "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "df.head(15)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRMtsJKBaxWu"
   },
   "source": [
    "## About the dataset\n",
    "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer: \n",
    "I believe in this case based on the wiki, the data provided is the features, whereas the targets provided are the labels. These labels are used to show the 3 different types flowers Setosa, versicolor and virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhKaIrZKNaHg"
   },
   "source": [
    "# Part 2: Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrgogB62NcOi",
    "outputId": "7bbfb1ea-88ed-4944-ab94-48696b9a71df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "\n",
    "\n",
    "features = df[[\"sepal length (cm)\" ,\"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"]]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = iris.target\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hblF-ei9Ncia"
   },
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhFhEN03Nf7o",
    "outputId": "15a94661-020b-4520-b5f3-c34fdfb042f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 1, 0, 1, 2, 0, 0, 2, 0, 1, 1, 2, 1, 1, 0, 2, 2, 0, 1,\n",
       "       0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 1, 2, 2, 0, 2, 1,\n",
       "       0, 1, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 1, 1, 1, 0, 0, 2, 1, 0, 1, 2,\n",
       "       2, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 1, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 1, 0, 1, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 1, 0,\n",
       "       2, 2, 0, 1, 1, 2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 2,\n",
       "       1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "LogReg = LogisticRegression(max_iter = 400).fit(X_train.values,y_train)\n",
    "LogReg.predict(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "iris.target_names[LogReg.predict(np.array([[5.0, 3.6, 1.4, 0.2]]))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.83571160e-01, 1.64288180e-02, 2.20157886e-08]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoint = np.array([[5.0, 3.6, 1.4, 0.2]])\n",
    "LogReg.predict_proba(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "LogReg.score(X_test.values, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score shows the accuracy in which it can predict what the flower it is based on the input parameters specified in LogReg.Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  [  9.64148594   2.13014426 -11.7716302 ]\n",
      "CoEfficient:  [[-0.42742786  0.9374586  -2.45189078 -1.05426314]\n",
      " [ 0.45681313 -0.24863004 -0.13813275 -0.91105511]\n",
      " [-0.02938527 -0.68882856  2.59002353  1.96531825]]\n"
     ]
    }
   ],
   "source": [
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "Y_intercept = LogReg.intercept_\n",
    "CoE = LogReg.coef_\n",
    "print(\"Intercept: \", Y_intercept)\n",
    "print(\"CoEfficient: \", CoE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDUpXQN4Nilk"
   },
   "source": [
    "# Part 4: Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U__zukpdNqiQ",
    "outputId": "5cd81a50-9137-4f36-842e-0687e9bc7c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto', probability=True))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "SupVM = make_pipeline(StandardScaler(), SVC(gamma='auto',  probability=True))\n",
    "SupVM.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 1, 0, 1, 2, 0, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 2, 0, 1,\n",
       "       0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 1,\n",
       "       0, 1, 2, 0, 0, 0, 0, 2, 2, 0, 2, 1, 1, 1, 1, 0, 0, 2, 1, 0, 1, 2,\n",
       "       2, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 2, 2, 2, 1, 2, 1, 0,\n",
       "       0, 2, 1, 2, 1, 1, 0, 1, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 1, 0,\n",
       "       2, 2, 0, 1, 1, 2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 2,\n",
       "       1, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "SupVM.predict(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names[SupVM.predict(np.array([[5.0, 3.6, 1.4, 0.2]]))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97713338, 0.01187251, 0.0109941 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SupVM.predict_proba(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "SupVM.score(X_test.values, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, both logistic regression and SVM appear to yield accurate results with a score of 1.0 proving to be able to predict 100% accuracy given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULoL7mMBNrlS"
   },
   "source": [
    "# Part 5: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKKmODVrN9lQ",
    "outputId": "dced24f7-c6bd-45fb-c68f-87548e9228dc"
   },
   "outputs": [],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "NN = MLPClassifier(random_state=1, max_iter=900).fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 1, 0, 1, 2, 0, 0, 2, 0, 1, 1, 2, 1, 1, 0, 2, 2, 0, 1,\n",
       "       0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 1,\n",
       "       0, 1, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 1, 1, 1, 0, 0, 2, 1, 0, 1, 2,\n",
       "       2, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 0,\n",
       "       0, 2, 1, 2, 1, 1, 0, 1, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 1, 0,\n",
       "       2, 2, 0, 1, 1, 2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 2,\n",
       "       1, 1, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "NN.predict(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names[NN.predict(np.array([[5.0, 3.6, 1.4, 0.2]]))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99241093e-01, 7.58906974e-04, 1.46973325e-14]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.predict_proba(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "\n",
    "NN.score(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iv: Experiment with different options for the neural network, \n",
    "#report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "\n",
    "#using Learning_rate constant\n",
    "NN2 = MLPClassifier(random_state=1, max_iter=900, learning_rate = 'constant').fit(X_train.values, y_train)\n",
    "NN2.predict(X_train.values)\n",
    "NN2.score(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN3 = MLPClassifier(random_state=1, max_iter=900, learning_rate = 'invscaling').fit(X_train.values, y_train)\n",
    "NN3.predict(X_train.values)\n",
    "NN3.score(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN4 = MLPClassifier(random_state=1, max_iter=900, learning_rate = 'adaptive').fit(X_train.values, y_train)\n",
    "NN4.predict(X_train.values)\n",
    "NN4.score(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using three other types of learning rates, my scores were still the same throughout the different usages. Its surprising to say that the usage of the MLP classifier yields a score of 0.97."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bi5tDwHmC28"
   },
   "source": [
    "# Part 6: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCFlfJy2mCg6",
    "outputId": "e71bf88c-6418-4b7f-e289-4acf743c16cc"
   },
   "outputs": [],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "\n",
    "kClass = KNeighborsClassifier(n_neighbors=6).fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found a pretty good article that ran me through the information regarding how logical regression is done. \n",
    "The article utilizies the use of the K-Nearest Neighbors. \n",
    "Link here: https://towardsdatascience.com/how-to-use-scikit-learn-datasets-for-machine-learning-d6493b38eca3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 1, 0, 1, 2, 0, 0, 1, 0, 1, 1, 2, 1, 1, 0, 2, 2, 0, 1,\n",
       "       0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 1, 2, 2, 0, 2, 1,\n",
       "       0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 2, 1, 1, 1, 1, 0, 0, 2, 1, 0, 1, 2,\n",
       "       2, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 2, 1, 0,\n",
       "       0, 2, 1, 2, 2, 1, 0, 1, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 1, 0,\n",
       "       2, 2, 0, 1, 1, 2, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 1, 1, 2, 2,\n",
       "       1, 1, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "kClass.predict(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names[kClass.predict(np.array([[5.0, 3.6, 1.4, 0.2]]))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kClass.predict_proba(datapoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, This one using logical regression prove to yield perfect numbers even in float form, this is very interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9703703703703703"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "kClass.score(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the k-neighborhood usage, the score doesn't do as well as the MLP via neural networks. This isn't suprising to me as neural network's use of MLP has more depth to it. Which utilizes a hidden layer mentioned in lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "162Sw3LeoqE2"
   },
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "\n",
    "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Regression\n",
    "The data gathered in logicial regression appears to yield very promosing results. The score in general yielded a 1.0 giving it the highest accuracy possible.\n",
    " \n",
    "# Support Vector Machine\n",
    "Like logical regression, SVM was also able to yield a score of 1.0. This was suprising that both were able maintain perfect accuracy give n data.\n",
    "\n",
    "# Neural Network\n",
    "Despite utilizing MLP, I was quite shocked that using this classification model was not able to match up to LR or SVM  ways to predict the data set on the iris. Even using different methods to try to improve the results yielded the same value. \n",
    " \n",
    "# K-Nearest Neighbor\n",
    "This was also quite interesting, that using a familiar algorithm was not able to yield a perfect score, despite using Logicial regression as its basis yielding a score of 0.96..... which was a little lower than Neural Network's MLP\n",
    "\n",
    "# Closing Thoughts\n",
    "\n",
    "I can see why Logical Regression and SVM prove to be very accurate, looking back at the usage of predict_proba for both LR, and SVM, the probablity of 1 of the three flowers for both classifications have a number close to/ over 1 yielding a confidence that it is likely the flower, where as the other remainder classifications had probabilities lesser than zero, or perfect numbers which is near impossible to be 100% accurate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
